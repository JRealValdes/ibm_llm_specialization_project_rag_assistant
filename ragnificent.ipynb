{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fd810e",
   "metadata": {},
   "source": [
    "# RAGnificent\n",
    "A Magnificent RAG for the IBM Specialization \"Generative AI Engineering with LLMs\" final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e18647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import (\n",
    "    PyMuPDFLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    JSONLoader,\n",
    "    WebBaseLoader,\n",
    "    TextLoader\n",
    ")\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used:\n",
    "facebook_chat_json_path = Path(\"documents\") / \"json\" / \"facebook_chat.json\"\n",
    "markdown_sample_path = 'documents\\markdown\\markdown-sample.md'\n",
    "lora_paper_pdf_path = 'documents\\pdf\\LoRA_paper.pdf'\n",
    "langchain_url = 'https://www.ibm.com/topics/langchain'\n",
    "new_policies_txt_path = Path(\"documents\") / \"txt\" / \"new_policies.txt\"\n",
    "\n",
    "# Unused:\n",
    "# mlb_teams_csv_path = 'documents\\csv\\mlb_teams_2012.csv'\n",
    "# large_scale_alignment_pdf_path = 'documents\\pdf\\large_scale_alignment.pdf'\n",
    "\n",
    "llm_model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
    "embedding_model_id = 'sentence-transformers/all-mpnet-base-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d82112",
   "metadata": {},
   "source": [
    "## Task 1 - Load document using LangChain for different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0dd80",
   "metadata": {},
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyMuPDFLoader(lora_paper_pdf_path)\n",
    "pdf_data = pdf_loader.load()\n",
    "print(pdf_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2a0f4",
   "metadata": {},
   "source": [
    "### Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a15a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_loader = UnstructuredMarkdownLoader(markdown_sample_path)\n",
    "md_data = md_loader.load()\n",
    "# print(md_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7762e",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_loader = JSONLoader(\n",
    "    file_path=facebook_chat_json_path,\n",
    "    jq_schema='.messages[].content',\n",
    "    text_content=False)\n",
    "\n",
    "json_data = json_loader.load()\n",
    "# print(json_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b259fa3",
   "metadata": {},
   "source": [
    "### Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce30d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_loader = WebBaseLoader(langchain_url)\n",
    "web_data = web_loader.load()\n",
    "# print(web_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e432b5",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_loader = TextLoader(new_policies_txt_path)\n",
    "txt_data = txt_loader.load()\n",
    "# print(txt_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ff9af",
   "metadata": {},
   "source": [
    "## Task 2 - Apply text splitting techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f565db6",
   "metadata": {},
   "source": [
    "### Recursive Character Text Splitter - On PDF file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = rc_text_splitter.create_documents([page.page_content for page in pdf_data])\n",
    "chunks_content = [chunk.page_content for chunk in chunks]\n",
    "print(f\"Number of chunks created from PDF: {len(chunks)}\")\n",
    "print(f\"First two chunks' content:\\n{chunks_content[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2f256",
   "metadata": {},
   "source": [
    "### Code Splitter on Python code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b434cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "    def hello_world():\n",
    "        print(\"Hello, World!\")\n",
    "    \n",
    "    # Call the function\n",
    "    hello_world()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbbc0c",
   "metadata": {},
   "source": [
    "## Task 3 - Embed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_embedding = HuggingFaceEmbeddings(model_name=embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ada38",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_embeddings = huggingface_embedding.embed_documents(chunks)\n",
    "print(f\"First 5 embeddings for the chunks:\\n{chunks_embeddings[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53145cb3",
   "metadata": {},
   "source": [
    "## Task 4 - Create and configure vector databases to store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fda3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [str(i) for i in range(0, len(chunks))]\n",
    "vectordb = Chroma.from_documents(chunks, huggingface_embedding, ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6b3e4",
   "metadata": {},
   "source": [
    "## Task 5 - Develop a retriever to fetch document segments based on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8918b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e382f34c",
   "metadata": {},
   "source": [
    "## Task 6 - Construct a QA Bot that leverages the LangChain and LLM to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How are you?\"\n",
    "\n",
    "query_result = huggingface_embedding.embed_query(query)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e695a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
